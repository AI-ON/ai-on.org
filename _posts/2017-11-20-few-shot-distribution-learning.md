---
Title: Few-Shot Distribution Learning for Music Generation
Tagline: Learn a generative model in the few-shot learning regime to generate MIDI sequences or lyrics.
Date: November 2017
Category: Fundamental Research
Contact: Hugo Larochelle (hugolarochelle@google.com), Chelsea Finn (cbfinn@eecs.berkeley.edu), Sachin Ravi (sachinr@princeton.edu)
Type: new
Authors: Hugo Larochelle, Chelsea Finn, Sachin Ravi
---

## Abstract

Few-shot distribution learning refers to the problem of learning a generative model
in the few-shot learning regime. We propose to investigate this problem in the
context of generating music data, such as lyrics or MIDI sequences, using ideas
from recent developments in adaptive language models, few-shot learning and
meta-learning. We plan to collect and construct benchmarks for this problem and
evaluate various solutions.


## Access the full proposal

- [Link to PDF](/pdf/larochelle-few-shot-distribution-learning.pdf)


## Resources

- [GitHub repository](https://github.com/AI-ON/Few-Shot-Music-Generation)
- [Slack channel](https://few-shot-music-gen.slack.com/join/shared_invite/enQtMjgwMTA0NTA3MzQ3LTA3MTc3M2E4MjEyNDlhZDNlMTU2ZmUyMmNmMDlhYmQ2ZmFkMDRiZTAzZDJmYmYwYmE0NjRmZGMyMmYxOWEzMWU)
- [Google group](https://groups.google.com/forum/#!forum/few-shot-music-generation)