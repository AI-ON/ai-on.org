<!doctype html>
<html>
<head>
    <meta charset="utf-8" />
    <!--[if IE]><meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1' /><![endif]-->

    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>AI•ON: Artificial Intelligence Open Network - Layer-wise supervised incremental training of residual networks</title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" href="/css/theme.css">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
</head>

<body>

    <div class="container">
      <h2 class="title"><span style="font-size: 1.7em">AI•ON</span> /aɪən/ <br> Artificial Intelligence <br> Open Network</h2>
      <div class="header">
        <nav>
          <ul class="nav nav-pills pull-xs-right">
            <li class="nav-item">
              <a class="nav-link" href="/">Home</a>
            </li>
            <li class="nav-item">
              <a class="nav-link active" href="/projects/">Projects</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/process/">Process</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="/about/">About</a>
            </li>
          </ul>
        </nav>
      </div>

      <div class="jumbotron">
        <a href="/projects/">❮❮ Back to projects list</a>
        <p>
            <b><h2>Layer-wise supervised incremental training of residual networks</h2></b>

            <h4>Date: October 2016</h4>
            <h4>Category: Fundamental Research</h4>
            <h4><a href="" target="_blank" title="">Project Repository</a></h4>

            
              <h4><a href="https://groups.google.com/d/forum/aion-incremental-training-of-residual-networks">Mailing list</a></h4>
            

            <hr>

            <p style="font-size: 12px;">
            <h2 id="problem-description">Problem description</h2>
<p>Due to their structure, it may be that residual modules [1] could be trained incrementally, starting from a previous, shallower net learned with full supervision. At each step, the network would learn an additional residual module, which would be an additional non-linear feature representation of the input that is fed into the previous module — the classifier. A very useful reading to help intuition of this effect is [2], which gives an ensemble-like interpretation of residual networks. The re-use of the previously trained layers should save computational time. Moreover, it is possible to show that at each step we are learning in a strictly larger model space, of which network learned in the previous step is the optimal model when we zero-out the weights of the new residual units just added.</p>
<p>Some approaches for incremental learning have been recently investigated [3, 4]. They share some intuition with this one. Although they try to solve the more general problem of transfer learning and they are not tailored to residual networks specifically.</p>
<h2 id="why-this-problem-matters">Why this problem matters</h2>
<p>Efficient layer-wise training of deep networks could allow to significantly speed up training of large models. It is one of the long-standing "dreams" of deep learning, but has proven elusive so far. If such a method were to be devised and performed competitively with end-to-end trained models while providing computational benefits, it would quickly be adopted across the entire field.</p>
<h2 id="datasets">Datasets</h2>
<ul>
<li><a href="http://image-net.org">ImageNet</a> - large-scale classification.</li>
<li><a href="https://github.com/openimages/dataset">OpenImages</a> - large-scale classification.</li>
<li><a href="http://mscoco.org/">MS COCO</a> - smaller scale classification, detection, segmentation.</li>
<li><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10</a> - small scale classification.</li>
</ul>
<h2 id="references">References</h2>
<ul>
<li>1: <a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></li>
<li>2: <a href="https://arxiv.org/abs/1605.06431">Residual Networks are Exponential Ensembles of Relatively Shallow Networks</a></li>
<li>3: <a href="https://arxiv.org/abs/1511.05641">Net2Net: Accelerating Learning via Knowledge Transfer</a></li>
<li>4: <a href="https://arxiv.org/abs/1606.04671">Progressive Neural Networks</a></li>
</ul>
            </p>

        </p>
      </div>

    </div>

</body>
</html>